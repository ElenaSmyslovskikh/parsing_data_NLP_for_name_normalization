{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import selenium\n",
    "import re\n",
    "import pandas as pd \n",
    "from selenium import webdriver as wb\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from urllib.parse import urljoin\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "br = wb.Chrome(r'')\n",
    "br.set_page_load_timeout(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls(url_page):\n",
    "    \n",
    "    try:\n",
    "        br.get(url_page)\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        r.status_code = 'Connection refused'\n",
    "    \n",
    "    response = requests.get(url_page)\n",
    "    soup = BeautifulSoup(response.text)\n",
    "    \n",
    "    urls_list = []\n",
    "    for i in soup.find_all('tr', attrs={'class': 'dark'}):\n",
    "        url_delo = 'http://opisi.garf.su/' + i.find('a', attrs={'class': 'dark'}).get('href')\n",
    "        urls_list.append(url_delo)\n",
    "        #sleep(0.5)\n",
    "          \n",
    "    return urls_list\n",
    "\n",
    "def urls_all_pages():\n",
    "    \n",
    "    list_1 = get_urls('http://opisi.garf.su/default.asp?base=garf&menu=2&v=5&node=655&fond=410&opis=149&co=502719&cd=2198709&cp=1')\n",
    "    \n",
    "    for n in range(2,428):\n",
    "        list_new = get_urls(f'http://opisi.garf.su/default.asp?base=garf&menu=2&v=5&node=655&fond=410&opis=149&cd=2203439&cp={n}')\n",
    "        list_1 = list_1.extend(list_new)\n",
    "      \n",
    "    return list_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = get_urls('http://opisi.garf.su/default.asp?base=garf&menu=2&v=5&node=655&fond=410&opis=149&co=502719&cd=2198709&cp=1')\n",
    "\n",
    "for n in range(351,428):\n",
    "    urls = urls\n",
    "    list_new = get_urls(f'http://opisi.garf.su/default.asp?base=garf&menu=2&v=5&node=655&fond=410&opis=149&cd=2203439&cp={n}')\n",
    "    print(n)\n",
    "    print(len(list_new))\n",
    "    if len(list_new) != 20:\n",
    "        print('С этой страницей возможно проблемы!')\n",
    "    urls.extend(list_new)\n",
    "    \n",
    "    with open(\"urls_2.txt\", \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(urls, fp)\n",
    "    \n",
    "    with open(\"urls_2.txt\", \"rb\") as fp:   # Unpickling\n",
    "        urls = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
